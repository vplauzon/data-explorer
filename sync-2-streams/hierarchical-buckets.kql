//  Let's re-create some sensor data
//  First we measure the "colour" of an asset every even seconds
.set-or-replace colours <| datatable(assetId:int, timeStamp:datetime, colour:string)
    [
    12, datetime(2020-1-1 20:00:04), "blue",
    12, datetime(2020-1-1 20:00:06), "blue",
    12, datetime(2020-1-1 20:00:08), "red",
    13, datetime(2020-1-1 20:00:04), "yellow",
    13, datetime(2020-1-1 20:00:06), "yellow",
    13, datetime(2020-1-1 20:00:08), "green",
    ];

//  Then we measure the temperature of an asset every odd seconds
.set-or-replace temperatures <| datatable(assetId:int, timeStamp:datetime, temperature:int)
    [
    12, datetime(2020-1-1 20:00:05), 20,
    12, datetime(2020-1-1 20:00:07), 22,
    12, datetime(2020-1-1 20:00:09), 25,
    13, datetime(2020-1-1 20:00:05), 15,
    13, datetime(2020-1-1 20:00:07), 13,
    13, datetime(2020-1-1 20:00:09), 10,
    ];

//  Let's create 10 millions records colour table (with 5000 assets)
.set-or-replace fullColours <|
(
    range i from 0 to 10000000 step 1
    | extend assetId = 1 + i % 5000
    | extend timeStep = i / 5000
    | extend timeStamp = datetime(2010-1-1 0:00:00) + timeStep * 2s
    | extend r = rand(3)
    | extend colour = case(r==0, "green", r==1, "yellow", "red")
    | project assetId, timeStamp, colour
)

//  Let's create 20 millions records (5000 assets) temperature table
//  It covers the same time range but with twice the measurement frequency
.set-or-replace fullTemperatures <|
(
    range i from 0 to 20000000 step 1
    | extend assetId = 1 + i % 5000
    | extend timeStep = i / 5000
    | extend timeStamp = datetime(2010-1-1 0:00:00) + timeStep * 1s
    | extend temperature = 10 + rand(25)
    | project assetId, timeStamp, temperature
)

//  Define extractTimeMapping as a function
//  We could easily reuse it this way
// Assuming T1 is smaller than T2 (for join order)
let extractTimeMapping = (
    T1:(assetId:long, timeStamp:datetime),
    T2:(assetId:long, timeStamp:datetime),
    maxDelta:timespan,
    subBucketCount:int) {
    let subBucketLength = 2 * maxDelta / subBucketCount;
    let minTimeStampT2 = toscalar(T2 | summarize min(timeStamp));
    let maxTimeStampT2 = toscalar(T2 | summarize max(timeStamp));
    //  Pre-compute max time stamp for each sub-buckets
    let preComputeMaxT2=range timeKey from bin(minTimeStampT2, subBucketLength) to bin(maxTimeStampT2, subBucketLength) step subBucketLength
    | join kind=inner
    (
        T2
        | extend timeKey = bin(timeStamp, subBucketLength)) on timeKey
    | summarize timeStamp=max(timeStamp) by assetId, timeKey;
    //  Augment T2 with a time key
    let withTimeKeysT2 = T2
    | extend timeKey = bin(timeStamp, subBucketLength);
    let mergedT2 = materialize(
    withTimeKeysT2
    | extend isPrimary=true
    | union
    (
        preComputeMaxT2
        | extend isPrimary=false
    ));
    //  Augment T1 with a time key, duplicating to catch earlier events in T2
    let withTimeKeysT1 = T1
    | extend timeKey = bin(timeStamp, subBucketLength)
    //  Introduce a constant to force cross-product
    | extend c=1
    | join kind=inner (range s from 0 to subBucketCount-1 step 1 | extend c=1) on c
    | project assetId, timeStamp, isPrimary=(s==0), timeKey=timeKey-(s*subBucketLength);
    //  Finally join the two sides
    let finalJoin = withTimeKeysT1
    | join kind=inner mergedT2 on assetId, timeKey
    | where timeStamp >= timeStamp1
    | summarize timeStampT2=max(timeStamp1) by assetId, timeStampT1=timeStamp;
    finalJoin
};
//  We simply normalize colours and temperatures table to fit expected schema
let colour1 = fullColours
| project assetId, timeStamp;
let temp1 = fullTemperatures
| project assetId, timeStamp;
extractTimeMapping(colour1, temp1, 5s, 40)