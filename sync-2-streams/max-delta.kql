//  Let's create some sensor data
//  First we measure the "colour" of an asset every even seconds
.set-or-replace colours <| datatable(assetId:long, timestamp:datetime, colour:string)
    [
    12, datetime(2020-1-1 20:00:04), "blue",
    12, datetime(2020-1-1 20:00:06), "blue",
    12, datetime(2020-1-1 20:00:08), "red",
    13, datetime(2020-1-1 20:00:04), "yellow",
    13, datetime(2020-1-1 20:00:06), "yellow",
    13, datetime(2020-1-1 20:00:08), "green",
    ];

//  Then we measure the temperature of an asset every odd seconds
.set-or-replace temperatures <| datatable(assetId:long, timestamp:datetime, temperature:int)
    [
    12, datetime(2020-1-1 20:00:05), 20,
    12, datetime(2020-1-1 20:00:07), 22,
    12, datetime(2020-1-1 20:00:09), 25,
    13, datetime(2020-1-1 20:00:05), 15,
    13, datetime(2020-1-1 20:00:07), 13,
    13, datetime(2020-1-1 20:00:09), 10,
    ];

//  If we join the two measures by asset-id, we get the usual cross-product
colours
| join kind=inner temperatures on assetId

//  We want to find the timestamp in temperatures that is the closest to the one in
//  colours ; we want one early or at the same time.
//  This is how we're going to eliminate the cross-product rows
//  Let's start by having the colour timestamp be greater or equal to temperature's
//  timestamp.
//  Instead of 18 records, that returns 12
//  Notice we lost the colour measure at 20:00:04 since there is no
//  earlier measure in temperature
colours
| join kind=inner temperatures on assetId
| where timestamp >= timestamp1

//  Now, let's take the largest temperature's timestamp
//  This gives us a mapping, by asset, of the 2 sensors timestamp
colours
| join kind=inner temperatures on assetId
| where timestamp >= timestamp1
| summarize temperaturetimestamp=max(timestamp1) by assetId, colourtimestamp=timestamp

//  Now, let's use that mapping to match the sensor values
//  Again we lost the two colour readings at 20:00:04 since
//  there was no temperature reading earlier or at the same time
let mapping=colours
| join kind=inner temperatures on assetId
| where timestamp >= timestamp1
| summarize temperaturetimestamp=max(timestamp1) by assetId, colourtimestamp=timestamp;
colours
| join kind=inner mapping on assetId
| where timestamp == colourtimestamp
| join kind=inner temperatures on assetId
| where timestamp1 == temperaturetimestamp
| project assetId, colourtimestamp, temperaturetimestamp, colour, temperature

//  Let's try this solution with volume
//  Let's create 10 millions records colour table (with 5000 assets)
.set-or-replace fullColours <|
(
    range i from 0 to 10000000 step 1
    | extend assetId = 1 + i % 5000
    | extend timeStep = i / 5000
    | extend timestamp = datetime(2010-1-1 0:00:00) + timeStep * 2s
    | extend r = rand(3)
    | extend colour = case(r==0, "green", r==1, "yellow", "red")
    | project assetId, timestamp, colour
)

//  Let's create 20 millions records (5000 assets) temperature table
//  It covers the same time range but with twice the measurement frequency
.set-or-replace fullTemperatures <|
(
    range i from 0 to 20000000 step 1
    | extend assetId = 1 + i % 5000
    | extend timeStep = i / 5000
    | extend timestamp = datetime(2010-1-1 0:00:00) + timeStep * 1s
    | extend temperature = 10 + rand(25)
    | project assetId, timestamp, temperature
)

//  Now, let's try the same solution on the bigger tables
//  This busts on a dev cluster:
//  either out-of-memory (cf https://docs.microsoft.com/en-us/azure/kusto/concepts/querylimits#limit-on-memory-per-iterator)
//  or time-out (cf https://docs.microsoft.com/en-us/azure/kusto/concepts/querylimits#limit-on-request-execution-time-timeout)
let mapping=fullColours
| join kind=inner fullTemperatures on assetId
| where timestamp <= timestamp1
| summarize temperaturetimestamp=min(timestamp1) by assetId, colourtimestamp=timestamp;
mapping
| limit 10

//  The reason this error occur is that we join and summarize on a very large table on the right side
//  We need to reduce the cardinality of the join
//  Let's try the approach laid out in
//  https://docs.microsoft.com/en-us/azure/kusto/query/join-timewindow
//  We quantitize time in bins.
//  The size of the bucket should be the longest time interval we expect
//  between the 2 sensors' reading.  This should be including clock
//  discrepencies.
//  We'll define and persist a core function doing the work
.create function extractTimeMapping(
    T1:(assetId:long, timestamp:datetime),
    T2:(assetId:long, timestamp:datetime),
    maxDelta:timespan) {
    let prepT1 = T1
        | project assetId, timestamp1=timestamp
        //  Create an array of 2 values for the time keys
        | extend timeKey=pack_array(
            bin(timestamp1-maxDelta, maxDelta),
            bin(timestamp1, maxDelta))
        //  Expand that array into 2 rows
        | mv-expand timeKey to typeof(datetime);
    let prepT2 = T2
        | project assetId, timestamp2=timestamp
        | extend timeKey=bin(timestamp2, maxDelta);
    let mapping = prepT1
    //  We use a left outer join to get a NULL value if we can't map
        | join kind=leftouter prepT2 on assetId, timeKey
        | where isnull(timestamp2) or timestamp1 >= timestamp2
        | summarize timestamp2=max(timestamp2) by assetId, timestamp1;
    mapping
}

//.drop function extractTimeMapping

//  Now let's try the mapping function on our small data set
//  Here we choose 60 seconds as a max-delta
let maxDelta = 60s;
extractTimeMapping(colours, temperatures, maxDelta)

//  We obtain the same result as before
//  Except we now explicitely show the null values
//  The result set is so small, it's not possible to measure how more
//  memory-efficient it was though
//  So let's try on the bigger result set
//  This runs in around 2 minutes on a Dev Cluster
.set-or-replace fullColoursWithTemperatures <|
let maxDelta = 60s;
extractTimeMapping(fullColours, fullTemperatures, maxDelta)

//  We can notice the cardinality of that last table is 10 000 001
//  The same cardinality than fullColours
fullColoursWithTemperatures
| count

//  Knowing our data set, we could lower the max-delta value
//  Let's try with 5 seconds to see if it improves performance significantly
//  This time, this runs in around 21 seconds on a Dev Cluster
.set-or-replace fullColoursWithTemperatures2 <|
let maxDelta = 5s;
extractTimeMapping(fullColours, fullTemperatures, maxDelta)

//  The cardinality is the same
fullColoursWithTemperatures2
| count

//  We can also validate the mappings are all identical
//  This performance improvement was possible because we knew we shouldn't have a delta of more than 2 seconds
fullColoursWithTemperatures
| join kind=leftanti fullColoursWithTemperatures2 on assetId, timestamp1, timestamp2
| count
